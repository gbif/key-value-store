# environment the application is running
# c3yarn.gbif-dev.org, but the alias isn't accepted
hadoop.jobtracker=c3master2-vh.gbif.org:8032
hdfs.namenode=hdfs://ha-nn
oozie.url=http://c3oozie.gbif-dev.org:11000/oozie

# Uses oozies shared lib and the /lib folder in the workflow
oozie.use.system.libpath=true

# hdfs because we do things like chown hbase:hbase
user.name=hdfs

# location of the workflow and jars
oozie.wf.application.path=hdfs://ha-nn/grscicoll-cache-workflow/workflow.xml
oozie.launcher.mapreduce.user.classpath.first=true
oozie.launcher.mapreduce.task.classpath.user.precedence=true

# Hive
grscicoll.cache.hive.hdfs.out=/user/hive/warehouse/dev.db
hive.metastore.uris=thrift://c3hivemetastore.gbif-dev.org:9083
occurrence_table_name=dev.occurrence
hive_db=marcos

// TODO: meter los de spark y oozie y hadoop


# Indexer
gbif.grscicoll.indexer.spark.opts=--executor-memory 4G --executor-cores 2 --num-executors 10 --conf spark.dynamicAllocation.enabled=false --conf spark.yarn.historyServer.address=http://c3master1-vh.gbif.org:18089 --conf spark.eventLog.dir=hdfs://ha-nn/user/spark/spark2ApplicationHistory --conf spark.eventLog.enabled=true
gbif.grscicoll.indexer.hbasezk=c3zk1.gbif-dev.org,c3zk2.gbif-dev.org,c3zk3.gbif-dev.org
gbif.grscicoll.indexer.targetTable=occurrence_collections
gbif.grscicoll.indexer.metastoreUris=thrift://c3hivemetastore.gbif.org:9083
gbif.grscicoll.indexer.hbaseTable=grscicoll_lookup_kv
gbif.grscicoll.indexer.baseApiUrl=http://api.gbif-dev.org/v1/
gbif.grscicoll.indexer.saltedKeyBuckets=10
gbif.grscicoll.indexer.apiTimeOut=6000
gbif.grscicoll.indexer.restClientCacheMaxSize=64